import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
data_to_load = files.upload()
%matplotlib inline
import warnings
import io
warnings.filterwarnings(action='ignore')
data = pd.read_csv(io.BytesIO(data_to_load['healthcare-dataset-stroke-data.csv']))
data.head(3)

data_row_count, data_column_count = data.shape
print('Row Count:', data_row_count)
print('Column Count:', data_column_count)

data.info()

data.isna().sum()

#---------------------------------------------------------------------------------------------
#fill missing value in bmi with values using Random Imputation technique
#assign object to the BMI (the only column that has missing values)
missing_columns = ['bmi']
def random_imputation(data, feature):

    number_missing = data[feature].isnull().sum()
    observed_values = data.loc[data[feature].notnull(), feature]
    data.loc[data[feature].isnull(), feature + '_imp'] = np.random.choice(observed_values, number_missing, replace = True)
    
    return data

for feature in missing_columns:
    data[feature + '_imp'] = data[feature]
    data = random_imputation(data, feature)
  

#data['bmi'] = data['bmi'].fillna(data['bmi'].mean())
data.info()

data.id.nunique()

data = data.drop(columns ='id')
data.shape

data.gender.value_counts()

data['gender'] = data['gender'].replace('Other', list(data.gender.mode().values)[0])
data.gender.value_counts()

df_cat = ['gender','hypertension','heart_disease','ever_married','work_type','Residence_type','smoking_status', 'stroke']

fig, axs = plt.subplots(4, 2, figsize=(14,20))
axs = axs.flatten()

# iterate through each column of df_catd and plot
for i, col_name in enumerate(df_cat):
    sns.countplot(x=col_name, data=data, ax=axs[i], hue=data['stroke'], palette='flare')
    plt.title("Bar chart of")
    axs[i].set_xlabel(f"{col_name}", weight = 'bold')
    axs[i].set_ylabel('Count', weight='bold')

#df_num = ['age', 'avg_glucose_level', 'bmi']
df_num = ['age', 'avg_glucose_level', 'bmi_imp']

fig, axs = plt.subplots(1, 3, figsize=(16,5))
axs = axs.flatten()

# iterate through each column in df_num and plot
for i, col_name in enumerate(df_num):
    sns.boxplot(x="stroke", y=col_name, data=data, ax=axs[i],  palette = 'Set1')
    axs[i].set_xlabel("Stroke", weight = 'bold')
    axs[i].set_ylabel(f"{col_name}", weight='bold')

bmi_outliers=data.loc[data['bmi_imp']>39]
bmi_outliers['bmi_imp'].shape

data["bmi_imp"] = pd.to_numeric(data["bmi_imp"])
data["bmi_imp"] = data["bmi_imp"].apply(lambda x: 39 if x>39 else x)

sns.boxplot(data=data,x=data["bmi_imp"],color='blue')
plt.title("Boxplot of BMI Distribution");

plt.figure(figsize=(4,4))
data['stroke'].value_counts().plot.pie(autopct='%1.1f%%', colors = ['#E7E01F','#81A3DC'])
plt.title("Pie Chart of Stroke Status", fontdict={'fontsize': 14})
plt.tight_layout()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

data['gender'] = le.fit_transform(data['gender'])
data['ever_married'] = le.fit_transform(data['ever_married'])
data['work_type'] = le.fit_transform(data['work_type'])
data['Residence_type'] = le.fit_transform(data['Residence_type'])
data['smoking_status'] = le.fit_transform(data['smoking_status'])

df_en = data
df_en.head()

#df_en = df_en.drop(['ever_married'], axis = 1)
#mna added
df_en = df_en.drop(['bmi'], axis = 1)
#df_en.head(3)

from sklearn.preprocessing import StandardScaler
s = StandardScaler()
columns = ['avg_glucose_level','bmi_imp','age']
stand_scaled = s.fit_transform(df_en[['avg_glucose_level','bmi_imp','age']])
stand_scaled = pd.DataFrame(stand_scaled,columns=columns)

df_en=df_en.drop(columns=columns,axis=1)
stand_scaled.head()

df = pd.concat([df_en, stand_scaled], axis=1)
df.head(3)

x=df.drop(['stroke'], axis=1)
y=df['stroke']

# Treating Imbalance Data using SMOTE
from imblearn.over_sampling import SMOTE
smote=SMOTE()
# to changeX & Y below to use data after rescaling
x_smote,y_smote=smote.fit_resample(x,y)


# Models
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

#from sklearn import tree
#clf=tree.DecisionTreeClassifier(random_state=0)
dtree = DecisionTreeClassifier()

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.cluster import KMeans

# Evaluation
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report


#original
#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=124)
#MNA edit
x_train, x_test, y_train, y_test = train_test_split(x_smote, y_smote, test_size=0.5, random_state=124)


models = dict()
models['Decision Tree'] = DecisionTreeClassifier()
models['Logreg'] = LogisticRegression()
models['Random Forest'] = RandomForestClassifier()
models['Support Vector Machine'] = SVC(kernel = 'sigmoid', gamma='scale')
models['kNN'] = KNeighborsClassifier()
models['Naive Bayes'] = GaussianNB()
models['KMeans'] = KMeans(n_clusters=2, n_init=10, random_state=42)
for model in models:
    
    models[model].fit(x_train, y_train)
    print(model + " model fitting completed.")

print("Test Set Prediction:\n")

for x in models:
    print('-'*20+x+'-'*20)
    model = models[x]
    y_pred = model.predict(x_test)
    arg_test = {'y_true':y_test, 'y_pred':y_pred}
    print(confusion_matrix(**arg_test))
    print(classification_report(**arg_test))

print('Summary of Accuracy Score\n\n')
for i in models:
    model = models[i]
    print(i + ' Model: ',accuracy_score(y_test, model.predict(x_test)).round(4))

from sklearn.model_selection import cross_val_score

gnb = GaussianNB()
